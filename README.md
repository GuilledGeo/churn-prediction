
# ðŸ”„ Churn Prediction System â€“ End-to-End ML Project

Este proyecto desarrolla un sistema completo de predicciÃ³n de abandono de clientes (churn), desde la exploraciÃ³n de datos hasta la creaciÃ³n de una API desplegable con `FastAPI` y `Docker`, pasando por modelado, testing y CI/CD. El objetivo es detectar quÃ© clientes tienen mayor probabilidad de causar baja, y anticiparse con acciones proactivas.

---

## ðŸ“¦ Dataset

- **Fuente**: Dataset pÃºblico simulado de churn de clientes de telecomunicaciones.
- **Contenido**: InformaciÃ³n de clientes (servicios, cargos, historial, contratos).
- **TamaÃ±o**: ~7.000 registros.
- **Objetivo (`Churn`)**: Variable binaria (1 = churn, 0 = no churn).

---

## ðŸŽ¯ Objetivos del proyecto

- Explorar los datos y entender patrones relacionados con el abandono.
- Construir modelos predictivos y evaluar su rendimiento.
- Crear una estructura modular de producciÃ³n con `src/`.
- Exportar modelos en `.pkl` y servir predicciones a travÃ©s de una API.
- Dockerizar la aplicaciÃ³n para despliegue eficiente.
- AÃ±adir tests, pre-commits y CI/CD con GitHub Actions.

---

## ðŸ§ª Proceso de desarrollo

### 1. ExploraciÃ³n de datos (EDA)

Se realizÃ³ un anÃ¡lisis con grÃ¡ficos y estadÃ­sticas:

- Distribuciones de `Churn`, cargos y duraciÃ³n del cliente (`tenure`).
- Variables categÃ³ricas como `Contract`, `PaymentMethod`, `OnlineSecurity`...
- Limpieza de `TotalCharges` y detecciÃ³n de valores atÃ­picos.

ðŸ“ UbicaciÃ³n: `notebooks/EDA.ipynb`
ðŸ“ Funciones reutilizadas: `src/data_prep/eda.py`

---

### 2. PreparaciÃ³n y limpieza

- ConversiÃ³n de tipos (`TotalCharges` numÃ©rico).
- CodificaciÃ³n con Label Encoding.
- DivisiÃ³n en `train/test` con estratificaciÃ³n.

ðŸ“ Funciones clave:
- `load_csv()` en `src/data_prep/load_data.py`
- `split_data()` en `src/features/build_features.py`

---

### 3. Modelado predictivo

Se entrenaron varios modelos usando `scikit-learn`:

| Modelo               | Accuracy | F1 (churn) | ROC AUC |
|----------------------|----------|------------|---------|
| Gradient Boosting    | 0.80     | 0.57       | 0.84 âœ… |
| Logistic Regression  | 0.74     | 0.62       | 0.83 âœ… |
| Random Forest        | 0.79     | 0.53       | 0.82    |
| SVM                  | 0.75     | 0.00       | 0.77 âŒ |
| KNN                  | 0.74     | 0.44       | 0.72 âŒ |

ðŸ“ Entrenamiento: `src/models/train_model.py`
ðŸ“ EvaluaciÃ³n: `src/models/evaluate_model.py`
ðŸ“ ExportaciÃ³n a `.pkl`: `outputs/models/`

ðŸ”® Se eligiÃ³ como modelo final `GradientBoostingClassifier`.

---

### 4. Estructura modular `src/`

Se creÃ³ un entorno modular para producciÃ³n:

```
src/
â”œâ”€â”€ data_prep/
â”‚   â”œâ”€â”€ load_data.py
â”‚   â””â”€â”€ eda.py
â”œâ”€â”€ features/
â”‚   â””â”€â”€ build_features.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluate_model.py
â”‚   â””â”€â”€ predict_model.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ retrain_and_export.py
```

---

### 5. API de predicciÃ³n con FastAPI

Se construyÃ³ una API con dos endpoints:

- `GET /` â†’ mensaje de estado
- `POST /predict` â†’ recibe JSON de cliente, devuelve predicciÃ³n y probabilidad

ðŸ“ CÃ³digo: `api/app.py`
ðŸ“ Cliente ejemplo: `predict.py`

---

### 6. DockerizaciÃ³n

La API se empaquetÃ³ con Docker:

- Imagen ligera basada en `python:3.10-slim`
- Se define `WORKDIR`, `COPY`, `RUN pip install`, `CMD`

ðŸ“ Dockerfile base
ðŸ“ Comandos en PowerShell (`make.ps1`):

```ps1
.\make.ps1 build     # Construye imagen
.\make.ps1 retrain   # Entrena modelo en contenedor
.\make.ps1 run       # Lanza API
.\make.ps1 clean     # Limpia modelos/cache
```

---

### 7. Testing

Se aÃ±adieron tests unitarios con `pytest`:

ðŸ“ Tests: `tests/test_train_model.py`, `tests/test_evaluate_model.py`

ðŸ“ ConfiguraciÃ³n: `pytest.ini`
```ini
[pytest]
pythonpath = .
```

---

### 8. CI/CD con GitHub Actions

Se configurÃ³ integraciÃ³n continua para:

- Ejecutar `pre-commit`
- Lanzar tests con `pytest`

ðŸ“ `.github/workflows/ci.yml`

```yaml
jobs:
  linter-and-tests:
    steps:
      - uses: actions/checkout@v3
      - name: Setup Python
      - name: Install deps + pytest
      - name: Run pre-commit
      - name: Run pytest
```

---

### 9. Pre-commit hooks

Se usan para mantener calidad de cÃ³digo (formato, estilo):

ðŸ“ `.pre-commit-config.yaml`
- `black`, `isort`, `trailing-whitespace`, `end-of-file-fixer`

---

## ðŸ“ˆ Resultados del modelo final

- **Modelo**: Gradient Boosting
- **Accuracy**: 0.80
- **F1-score (Churn)**: 0.57
- **ROC AUC**: 0.84
- **Top variables**:
  - `MonthlyCharges`
  - `tenure`
  - `TotalCharges`
  - `Contract`
  - `TechSupport`, `OnlineSecurity`

---

## ðŸ§  Lecciones aprendidas

- CÃ³mo preparar un proyecto ML profesional de extremo a extremo
- Separar lÃ³gica por mÃ³dulos (`src/`)
- Dockerizar una API de ML
- AÃ±adir testing y CI/CD para producciÃ³n robusta

---

## ðŸš€ Para lanzar la API localmente con Docker

```bash
.\make.ps1 build
.\make.ps1 retrain
.\make.ps1 run
```

Luego visita: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## ðŸ“« Contacto

- ðŸ“§ Email: guillermodurantez@gmail.com
- ðŸ”— [LinkedIn](https://www.linkedin.com/in/guillermodurantez/)

> â­ Este proyecto forma parte de mi portfolio de ciencia de datos.
> Repositorio: [github.com/GuilledGeo/churn-prediction](https://github.com/GuilledGeo/churn-prediction)
